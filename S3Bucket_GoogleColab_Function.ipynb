{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNq0sdPGVkl1",
        "outputId": "a10c8aca-04b7-48d5-e05c-3a5cf08565e0"
      },
      "outputs": [],
      "source": [
        "# aws_access_key_id = 'AKIA6GBMB6KOCGR7U6EQ'\n",
        "# aws_secret_access_key = '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'\n",
        "import os\n",
        "import boto3\n",
        "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
        "\n",
        "def setup_and_download_from_s3(aws_access_key_id, aws_secret_access_key, bucket_name, s3_folder, local_dir=None):\n",
        "    \"\"\"\n",
        "    This function sets up the AWS S3 client and downloads the files from the S3 bucket to the local directory.\n",
        "\n",
        "    Parameters:\n",
        "    aws_access_key_id (str): AWS access key ID.\n",
        "    aws_secret_access_key (str): AWS secret access key.\n",
        "    bucket_name (str): Name of the S3 bucket.\n",
        "    s3_folder (str): Folder in the S3 bucket to download.\n",
        "    local_dir (str, optional): Local directory to download the files to. Defaults to the S3 folder name.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an S3 client\n",
        "    try:\n",
        "        # Here we create an S3 client using the boto3 library\n",
        "        s3_client = boto3.client(\n",
        "            's3',\n",
        "            # The AWS credentials are passed to the client\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key\n",
        "        )\n",
        "    except PartialCredentialsError:\n",
        "        print(\"Your AWS credentials are incomplete.\")\n",
        "        return\n",
        "    except NoCredentialsError:\n",
        "        print(\"Your AWS credentials were not found.\")\n",
        "        return\n",
        "    # Input of function is the bucket name (which will be cvdeeplearningfiltered),\n",
        "    # the S3 folder which can either be: Training, Validation or Test\n",
        "    def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
        "        if local_dir is None:\n",
        "            local_dir = s3_folder\n",
        "        # AWS S3 paginators are used to retrieve the objects in the bucket in multiple pages\n",
        "        paginator = s3_client.get_paginator('list_objects_v2')\n",
        "        try:\n",
        "            # Iterate over every object on current page\n",
        "            for page in paginator.paginate(Bucket=bucket_name, Prefix=s3_folder):\n",
        "                for obj in page.get('Contents', []):\n",
        "                    # Captures the key associate with each image (file)\n",
        "                    file_key = obj['Key']\n",
        "                    if file_key.endswith('/'):\n",
        "                        continue  # skip directories\n",
        "                    local_file_path = os.path.join(local_dir, os.path.basename(file_key))\n",
        "                    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
        "                    # Actual downloading of S3 object to local file path\n",
        "                    s3_client.download_file(bucket_name, file_key, local_file_path)\n",
        "                    print(f\"Downloaded {file_key} to {local_file_path}\")\n",
        "        except NoCredentialsError:\n",
        "            print(\"Invalid AWS credentials\")\n",
        "        except s3_client.exceptions.NoSuchBucket:\n",
        "            print(\"The bucket does not exist or you have no access.\")\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    # Call the download function\n",
        "    download_s3_folder(bucket_name, s3_folder, local_dir)\n",
        "\n",
        "# These are the credentials for the AWS S3 bucket. They will be used to authenticate the client and are consistent for all users.\n",
        "aws_access_key_id = 'AKIA6GBMB6KOCGR7U6EQ'\n",
        "aws_secret_access_key = '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'\n",
        "bucket_name = 'deeplearningcvfood'\n",
        "\n",
        "# The different choices for the s3_folder are: Training, Validation or Test\n",
        "s3_folder = 'public_test_release_2.0/'\n",
        "local_dir = '/content/drive/My Drive/Project_1/S3_Data/Test/'\n",
        "\n",
        "# Call the function\n",
        "setup_and_download_from_s3(aws_access_key_id, aws_secret_access_key, bucket_name, s3_folder, local_dir)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
