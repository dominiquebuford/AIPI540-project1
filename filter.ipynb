{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data\n",
    "In this section we will be fixing the dataset (correcting size mismatch) and preparing to to feed into our model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# utilities\n",
    "from pprint import pprint # For beautiful print!\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# For data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "\n",
    "# For reading annotations file\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "TRAIN_ANNOTATIONS_PATH = \"../bigdata/train/new_ann.json\"\n",
    "TRAIN_IMAGE_DIRECTIORY = \"../bigdata/train/images/\"\n",
    "\n",
    "VAL_ANNOTATIONS_PATH = \"../bigdata/val/new_ann.json\"\n",
    "VAL_IMAGE_DIRECTIORY = \"../bigdata/val/images/\"\n",
    "\n",
    "# Reading the annotation files\n",
    "with open(TRAIN_ANNOTATIONS_PATH) as f:\n",
    "  train_annotations_data = json.load(f)\n",
    "\n",
    "with open(VAL_ANNOTATIONS_PATH) as f:\n",
    "  val_annotations_data = json.load(f)\n",
    "\n",
    "train_coco = COCO(TRAIN_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the space at the end of the category names if they have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the space at the end of the category names if they have one\n",
    "for category in train_annotations_data['categories']:\n",
    "  category['name_readable'] = category['name_readable'].strip()\n",
    "\n",
    "for category in val_annotations_data['categories']:\n",
    "  category['name_readable'] = category['name_readable'].strip()\n",
    "\n",
    "for category in train_coco.dataset['categories']:\n",
    "  category['name_readable'] = category['name_readable'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary (key: name_readable, value: id) that only contains food categories that belong in a kid's diet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bread, wholemeal': 1565, 'Jam': 2099, 'Water': 2578, 'Bread, sourdough': 1556, 'Banana': 1154, 'Soft cheese': 1352, 'Ham, raw': 1893, 'Hard cheese': 1310, 'Cottage cheese': 1264, 'Bread, half white': 1536, 'Coffee, with caffeine': 2512, 'Fruit salad': 1166, 'Pancakes': 2949, 'Tea': 2498, 'Salmon, smoked': 2973, 'Avocado': 1056, 'Spring onion / scallion': 1111, 'Ristretto, with caffeine': 2524, 'Ham': 1886, 'Egg': 2022, 'Bacon, frying': 1915, 'Chips, french fries': 1013, 'Juice, apple': 2446, 'Chicken': 1788, 'Tomato, raw': 1069, 'Broccoli': 1085, 'Shrimp, boiled': 259, 'Beetroot, steamed, without addition of salt': 50, 'Carrot, raw': 1078, 'Chickpeas': 1143, 'French salad dressing': 2743, 'Pasta, Hörnli': 1487, 'Sauce, cream': 2730, 'Meat balls': 8025, 'Pasta': 1483, 'Tomato sauce': 2738, 'Cheese': 1311, 'Pear': 1157, 'Cashew nut': 1213, 'Almonds': 1210, 'Lentils': 1144, 'Mixed vegetables': 1022, 'Peanut butter': 1203, 'Apple': 1151, 'Blueberries': 1169, 'Cucumber': 1061, 'Cocoa powder': 2171, 'Greek Yaourt, yahourt, yogourt ou yoghourt': 3332, 'Maple syrup (Concentrate)': 2115, 'Buckwheat, grain peeled': 3181, 'Butter': 2053, 'Herbal tea': 2555, 'Mayonnaise': 2750, 'Soup, vegetable': 2836, 'Wine, red': 2618, 'Wine, white': 2620, 'Green bean, steamed, without addition of salt': 387, 'Sausage': 1924, 'Pizza, Margherita, baked': 2939, 'Salami': 1879, 'Mushroom': 1098, '(bread, meat substitute, lettuce, sauce)': 3739, 'Tart': 2350, 'Tea, verveine': 2543, 'Rice': 1468, 'White coffee, with caffeine': 2521, 'Linseeds': 1222, 'Sunflower seeds': 1208, 'Ham, cooked': 1889, 'Bell pepper, red, raw': 1068, 'Zucchini': 1070, 'Green asparagus': 1123, 'Tartar sauce': 2751, 'Lye pretzel (soft)': 1595, 'Cucumber, pickled': 1060, 'Curry, vegetarian': 3630, 'Yaourt, yahourt, yogourt ou yoghourt, natural': 5641, 'Soup of lentils, Dahl (Dhal)': 3358, 'Soup, cream of vegetables': 2837, 'Balsamic vinegar': 2815, 'Salmon': 1967, 'Salt cake (vegetables, filled)': 2923, 'Bacon': 1914, 'Orange': 1187, 'Pasta, noodles': 1494, 'Cream': 1376, 'Cake, chocolate': 2303, 'Pasta, spaghetti': 1505, 'Black olives': 1229, 'Parmesan': 1323, 'Spaetzle': 1482, \"Salad, lambs' ear\": 1050, 'Salad, leaf / salad, green': 1040, 'Potatoes steamed': 1010, 'White cabbage': 1094, 'Halloumi': 1309, 'Beetroot, raw': 1075, 'Bread, grain': 1538, 'Applesauce, unsweetened, canned': 727, 'Cheese for raclette': 1327, 'Mushrooms': 1102, 'Bread, white': 1566, 'Curds, natural, with at most 10% fidm': 870, 'Bagel (without filling)': 1517, 'Quiche, with cheese, baked, with puff pastry': 732, 'Soup, potato': 2840, 'Bouillon, vegetable': 2859, 'Beef, sirloin steak': 1727, 'Taboulé, prepared, with couscous': 2967, 'Eggplant': 1055, 'Bread': 1522, 'Turnover with meat (small meat pie, empanadas)': 3399, 'Mungbean sprouts': 1121, 'Mozzarella': 1321, 'Pasta, penne': 1496, 'Lasagne, vegetable, prepared': 3415, 'Mandarine': 1180, 'Kiwi': 1176, 'French beans': 1058, 'Tartar (meat)': 4335, 'Spring roll (fried)': 2918, 'Pork, chop': 1757, 'Caprese salad (Tomato Mozzarella)': 2964, 'Leaf spinach': 1032, 'Roll of half-white or white flour, with large void': 1569, 'Pasta, ravioli, stuffing': 1500, 'Omelette, plain': 2320, 'Tuna': 1980, 'Dark chocolate': 2131, 'Sauce (savoury)': 2711, 'Dried raisins': 1199, 'Ice tea': 2470, 'Kaki': 1174, 'Macaroon': 2395, 'Smoothie': 2461, 'Crêpe, plain': 2269, 'Chicken nuggets': 1837, 'Chili con carne, prepared': 2966, 'Veggie burger': 1942, 'Cream spinach': 5792, 'Cod': 1958, 'Chinese cabbage': 1086, 'Hamburger (Bread, meat, ketchup)': 2930, 'Soup, pumpkin': 2841, 'Sushi': 2944, 'Chestnuts': 1204, 'Coffee, decaffeinated': 2513, 'Sauce, soya': 2807, 'Balsamic salad dressing': 2742, 'Pasta, twist': 1506, 'Bolognaise sauce': 2736, 'Leek': 1113, 'Fajita (bread only)': 3221, 'Potato-gnocchi': 1009, 'Beef, cut into stripes (only meat)': 1731, 'Rice noodles/vermicelli': 1453, 'Tea, ginger': 2553, 'Tea, green': 2530, 'Bread, whole wheat': 1554, 'Onion': 1116, 'Garlic': 1112, 'Hummus': 2952, 'Pizza, with vegetables, baked': 633, 'Beer': 2634, 'Glucose drink 50g': 3080, 'Chicken, wing': 1791, 'Ratatouille': 1024, 'Peanut': 1214, 'High protein pasta (made of lentils, peas, ...)': 8730, 'Cauliflower': 1084, 'Quiche, with spinach, baked, with cake dough': 733, 'Green olives': 1228, 'Brazil nut': 1218, 'Eggplant caviar': 2991, 'Bread, pita': 1547, 'Pasta, wholemeal': 1513, 'Sauce, pesto': 2728, 'Oil': 2031, 'Couscous': 1455, 'Sauce, roast': 2714, 'Prosecco': 2607, 'Crackers': 2899, 'Bread, toast': 1560, 'Shrimp / prawn (small)': 1985, 'Panna cotta': 1367, 'Romanesco': 1090, 'Water with lemon juice': 3262, 'Espresso, with caffeine': 2504, 'Egg, scrambled, prepared': 3042, 'Juice, orange': 2454, 'Ice cubes': 2577, 'Braided white loaf': 1607, 'Emmental cheese': 1293, 'Croissant, wholegrain': 1592, 'Hazelnut-chocolate spread(Nutella, Ovomaltine, Caotina)': 2172, 'Tomme': 1348, 'Water, mineral': 2580, 'Hazelnut': 1215, 'Bacon, raw': 1917, 'Bread, nut': 1545, 'Black Forest Tart': 2340, 'Soup, Miso': 2846, 'Peach': 1190, 'Figs': 1164, 'Beef, filet': 1728, 'Mustard, Dijon': 2811, 'Rice, Basmati': 1469, 'Mashed potatoes, prepared, with full fat milk, with butter': 2935, 'Dumplings': 2959, 'Pumpkin': 1065, 'Swiss chard': 1120, 'Red cabbage': 1092, 'Spinach, raw': 282, 'Naan (indien bread)': 3248, 'Chicken curry (cream/coconut milk. curry spices/paste))': 3100, 'Crunch Müesli': 1627, 'Biscuits': 2388, 'Bread, French (white flour)': 1520, 'Meatloaf': 1845, 'Fresh cheese': 1300, 'Honey': 2103, 'Vegetable mix, peas and carrots': 1019, 'Parsley': 2773, 'Brownie': 2254, 'Dairy ice cream': 1402, 'Tea, black': 2534, 'Carrot cake': 2333, 'Fish fingers (breaded)': 2003, 'Salad dressing': 2741, 'Dried meat': 1853, 'Chicken, breast': 1789, 'Mixed salad (chopped without sauce)': 1026, 'Feta': 1294, 'Praline': 2073, 'Tea, peppermint': 2562, 'Walnut': 1212, 'Potato salad, with mayonnaise yogurt dressing': 780, 'Kebab in pita bread': 2947, 'Kolhrabi': 1089, 'Alfa sprouts': 1126, 'Brussel sprouts': 1091, 'Bacon, cooking': 1916, 'Gruyère': 1307, 'Bulgur': 1454, 'Grapes': 1198, 'Pork, escalope': 1760, 'Chocolate egg, small': 2194, 'Cappuccino': 2501, 'Zucchini, stewed, without addition of fat, without addition of salt': 232, 'Crisp bread, Wasa': 1612, 'Bread, black': 1557, 'Perch fillets (lake)': 2968, 'Rosti': 1014, 'Mango': 1181, 'Sandwich (ham, cheese and butter)': 2941, 'Müesli': 1670, 'Spinach, steamed, without addition of salt': 281, 'Fish': 1956, 'Risotto, without cheese, cooked': 2970, 'Milk Chocolate with hazelnuts': 5618, 'Cake (oblong)': 2259, 'Crisps': 2905, 'Pork': 1748, 'Pomegranate': 1152, 'Sweet corn, canned': 483, 'Flakes, oat': 1422, 'Greek salad': 2954, 'Cantonese fried rice': 5812, 'Sesame seeds': 1223, 'Bouillon': 2855, 'Baked potato': 10626, 'Fennel': 1119, 'Meat': 1707, 'Bread, olive': 1546, 'Croutons': 2900, 'Philadelphia': 1325, 'Mushroom, (average), stewed, without addition of fat, without addition of salt': 158, 'Bell pepper, red, stewed, without addition of fat, without addition of salt': 656, 'White chocolate': 2133, 'Mixed nuts': 1220, 'Breadcrumbs (unspiced)': 1614, 'Fondue': 1295, 'Sauce, mushroom': 2729, 'Tea, spice': 2548, 'Strawberries': 1163, 'Tea, rooibos': 2563, 'Pie, plum, baked, with cake dough': 3101, 'Potatoes au gratin, dauphinois, prepared': 3115, 'Capers': 1062, 'Vegetables': 1021, 'Bread, wholemeal toast': 1561, 'Red radish': 1074, 'Fruit tart': 2278, 'Beans, kidney': 1138, 'Sauerkraut': 1093, 'Mustard': 2810, 'Country fries': 1007, 'Ketchup': 2734, 'Pasta, linguini, parpadelle, Tagliatelle': 1490, 'Chicken, cut into stripes (only meat)': 1793, 'Cookies': 2376, 'Sun-dried tomatoe': 3293, 'Bread, Ticino': 1559, 'Semi-hard cheese': 1308, 'Margarine': 2062, 'Porridge, prepared, with partially skimmed milk': 3615, 'Soya drink (soy milk)': 1256, 'Juice, multifruit': 2452, 'Popcorn salted': 2906, 'Chocolate, filled': 2135, 'Milk chocolate': 2132, 'Bread, fruit': 1533, 'Mix of dried fruits and nuts': 9594, 'Corn': 1108, 'Tête de Moine': 1346, 'Dates': 1162, 'Pistachio': 1221, 'Celery': 1130, 'White radish': 1076, 'Oat milk': 3046, 'Cream cheese': 1328, 'Bread, rye': 1551, 'Witloof chicory': 1033, 'Apple crumble': 2994, 'Goat cheese (soft)': 6404, 'Grapefruit, pomelo': 1167, 'Risotto, with mushrooms, cooked': 752, 'Blue mould cheese': 1280, 'Biscuit with Butter': 2408, 'Guacamole': 2749, 'Pecan nut': 1219, 'Tofu': 1948, 'Cordon bleu, from pork schnitzel, fried': 2932, 'Paprika chips': 5689, 'Quinoa': 1467, 'Kefir drink': 1249, \"M&M's\": 2184, 'Salad, rocket': 1038, 'Bread, spelt': 1528, 'Pizza, with ham, with mushrooms, baked': 629, 'Fruit coulis': 3308, 'Plums': 1191, 'Beef, minced (only meat)': 1730, 'Pizza, with ham, baked': 630, 'Pineapple': 1150, 'Soup, tomato': 2852, 'Cheddar': 1290, 'Tea, fruit': 2546, 'Rice, Jasmin': 1471, 'Seeds': 1205, 'Focaccia': 1587, 'Milk': 1237, 'Coleslaw (chopped without sauce)': 1020, 'Pastry, flaky': 1696, 'Curd': 1266, 'Savoury puff pastry stick': 2896, 'Sweet potato': 1004, 'Chicken, leg': 1794, 'Croissant': 1588, 'Sour cream': 1383, 'Ham, turkey': 1895, 'Processed cheese': 1337, 'Fruit compotes': 3474, 'Cheesecake': 2962, 'Pasta, tortelloni, stuffing': 1509, 'Sauce, cocktail': 2718, 'Croissant with chocolate filling': 2362, 'Pumpkin seeds': 1206, 'Artichoke': 1054, 'Champagne': 2605, 'Grissini': 1616, 'Sweets / candies': 2203, 'Brie': 1282, 'Wienerli (Swiss sausage)': 843, 'Syrup (diluted, ready to drink)': 2495, 'Apple pie': 2237, 'White bread with butter, eggs and milk': 1584, 'Savoury puff pastry': 2895, 'Anchovies': 1975, 'Tuna, in oil, drained': 922, 'Lemon pie': 3055, 'Meat terrine, paté': 1919, 'Coriander': 2767, 'Falafel (balls)': 2873, 'Berries': 1156, 'Latte macchiato, with caffeine': 2518, 'Faux-mage Cashew, vegan chers': 5247, 'Beans, white': 1141, 'Sugar Melon': 1184, 'Mixed seeds': 1209, 'Hamburger': 1849, 'Hamburger bun': 1572, 'Oil & vinegar salad dressing': 2747, 'Soya Yaourt, yahourt, yogourt ou yoghourt': 1257, 'Chocolate milk, chocolate drink': 3258, 'Celeriac': 1082, 'Chocolate mousse': 2961, 'Cenovis, yeast spread': 2791, 'Thickened cream (> 35%)': 1384, 'Meringue': 2400, 'Lamb, chop': 1770, 'Shrimp / prawn (large)': 1986, 'Beef': 1724, 'Lemon': 1200, 'Croque monsieur': 2913, 'Chives': 2778, 'Chocolate cookies': 2413, 'Birchermüesli, prepared, no sugar added': 3220, 'Fish crunchies (battered)': 2002, 'Muffin': 2312, 'Savoy cabbage, steamed, without addition of salt': 198, 'Pine nuts': 1207, 'Chorizo': 1838, 'Chia grains': 4338, 'Frying sausage': 1831, 'French pizza from Alsace, baked': 3417, 'Chocolate': 2134, 'Cooked sausage': 1883, 'Grits, polenta, maize flour': 1463, 'Gummi bears, fruit jellies, Jelly babies with fruit essence': 2211, 'Wine, rosé': 2616, 'Coca Cola': 2467, 'Raspberries': 1170, 'Roll with pieces of chocolate': 1580, 'Goat, (average), raw': 3082, 'Lemon Cake': 2262, 'Coconut milk': 1253, 'Rice, wild': 1479, 'Gluten-free bread': 3306, 'Pearl onions': 1115, 'Buckwheat pancake': 7504, 'Bread, 5-grain': 1523, 'Light beer': 2636, 'Sugar, glazing': 2113, 'Tzatziki': 2752, 'Butter, herb': 2056, 'Ham croissant': 2920, 'Corn crisps': 2898, 'Lentils green (du Puy, du Berry)': 3230, 'Cocktail': 2588, 'Rice, whole-grain': 1478, 'Veal sausage': 1856, 'Cervelat': 1835, 'Sorbet': 1411, 'Aperitif, with alcohol, apérol, Spritz': 2585, 'Dips': 2740, 'Corn Flakes': 1626, 'Peas': 1107, 'Tiramisu': 1371, 'Apricots': 1153, 'Cake, marble': 2300, 'Lamb': 1765, 'Lasagne, meat, prepared': 2934, 'Coca Cola Zero': 2468, 'Cake, salted': 3337, 'Dough (puff pastry, shortcrust, bread, pizza dough)': 1695, 'Rice waffels': 1615, 'Sekt': 2610, 'Brioche': 1568, 'Vegetable au gratin, baked': 3532, 'Mango dried': 3228, 'Processed meat, Charcuterie': 1857, 'Mousse': 1366, 'Sauce, sweet & sour': 2731, 'Basil': 2760, 'Butter, spread, puree almond': 3249, 'Pie, apricot, baked, with cake dough': 2990, 'Rusk, wholemeal': 1620, 'Beef, roast': 1725, 'Vanille cream, cooked, Custard, Crème dessert': 236, 'Pasta in conch form': 1492, 'Nuts': 1211, 'Sauce, carbonara': 2716, 'Fig, dried': 3392, 'Pasta in butterfly form, farfalle': 1488, 'Minced meat': 1711, 'Carrot, steamed, without addition of salt': 143, 'Ebly': 1456, 'Damson plum': 1201, 'Shoots': 1125, 'Bouquet garni': 2768, 'Coconut': 1216, 'Banana cake': 5748, 'Waffle': 2355, 'Apricot, dried': 2960, 'Sauce, curry': 2719, 'Watermelon, fresh': 578, 'Sauce, sweet-salted (asian)': 3416, 'Pork, roast': 1749, 'Blackberry': 1158, 'Smoked cooked sausage of pork and beef meat sausag': 1908, 'bean seeds': 1134, 'Italian salad dressing': 2744, 'White asparagus': 1124, 'Pie, rhubarb, baked, with cake dough': 3085, 'Tomato, stewed, without addition of fat, without addition of salt': 929, 'Cherries': 1175, 'Nectarine': 1186}\n",
      "102\n",
      "{1536, 1024, 2053, 5641, 2578, 1556, 2580, 1565, 1566, 1056, 1060, 1061, 1068, 1069, 1070, 2099, 1588, 1078, 1085, 2115, 1098, 2134, 633, 1151, 1154, 1157, 1670, 1163, 1166, 1169, 1176, 1180, 1187, 2730, 1198, 2738, 1203, 1206, 3258, 1237, 727, 732, 2269, 1264, 1788, 2303, 1791, 1794, 3332, 1293, 2320, 2836, 2837, 2840, 2841, 281, 1310, 1311, 1321, 1837, 1327, 1352, 2388, 8025, 1886, 1376, 1889, 1895, 2930, 1914, 2939, 1915, 2941, 387, 1924, 2949, 2446, 3474, 2962, 2966, 1942, 2454, 2461, 1956, 2470, 1958, 1967, 1468, 1980, 1483, 1487, 1494, 1496, 1505, 2022, 1004, 1517, 1010, 1522, 1013, 1020, 1022}\n"
     ]
    }
   ],
   "source": [
    "# Reading all classes\n",
    "category_ids = train_coco.loadCats(train_coco.getCatIds())\n",
    "category_names = [_[\"name_readable\"] for _ in category_ids]\n",
    "\n",
    "# create a dictionary with category id as key and category name as value\n",
    "all_category_dict = dict()\n",
    "for d in category_ids:\n",
    "    name = d[\"name_readable\"].strip()\n",
    "    all_category_dict[name] = d[\"id\"]\n",
    "\n",
    "print(all_category_dict)\n",
    "\n",
    "# create a list of kids categories from the file foods-for-kids.txt\n",
    "kids_category_list = list()\n",
    "with open('files/foods-for-kids.txt', \"r\") as file:\n",
    "    for line in file:\n",
    "        item = line.strip()\n",
    "        kids_category_list.append(item)\n",
    "\n",
    "# create new dictionary with only kids ids\n",
    "kids_category_ids = set()\n",
    "for key in list(all_category_dict.keys()):\n",
    "    if key in kids_category_list:\n",
    "        kids_category_ids.add(all_category_dict[key])\n",
    "\n",
    "print(len(kids_category_ids))\n",
    "print(kids_category_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all categories dict in dictionary format to a text file\n",
    "with open('files/foods-for-kids-dict.txt', 'w') as file:\n",
    "    file.write(json.dumps(all_category_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_category_ids(data, kids_category_ids):\n",
    "    \"\"\"\n",
    "    Gets the category ids for each category in data[categories] that has a name in all_category_dict\n",
    "\n",
    "    Input:\n",
    "    data: json file with annotations\n",
    "    all_category_dict: dictionary with category names as keys and category ids as values\n",
    "\n",
    "    Returns:\n",
    "    filtered_category_ids: list of category ids for each category in data[categories] that has a name in all_category_dict\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_category_ids = set()\n",
    "    for category in data['categories']:\n",
    "        if category['id'] in kids_category_ids:\n",
    "            filtered_category_ids.add(category['id'])\n",
    "\n",
    "    return filtered_category_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_annotation_ids(data, kids_category_ids):\n",
    "    \"\"\"\n",
    "    Gets the annotation ids for each annotation in data[annotation] that has a category in all_category_dict\n",
    "\n",
    "    Input:\n",
    "    data: json file with annotations\n",
    "    all_category_dict: dictionary with category names as keys and category ids as values\n",
    "\n",
    "    Returns:\n",
    "    filtered_annotation_ids: list of annotation ids for each annotation in data[annotation] that has a category in all_category_dict\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_annotation_ids = set()\n",
    "    for annotation in data['annotations']:\n",
    "        if annotation['category_id'] in kids_category_ids:\n",
    "            filtered_annotation_ids.add(annotation['id'])\n",
    "\n",
    "    return filtered_annotation_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_image_ids(data, filtered_annotation_ids):\n",
    "    \"\"\"\n",
    "    Gets the image ids for each image in data[images] that has an annotation in filtered_annotation_ids\n",
    "\n",
    "    Input:\n",
    "    data: json file with annotations\n",
    "    filtered_annotation_ids: list of annotation ids for each annotation in data[annotation] that has a category in all_category_dict\n",
    "\n",
    "    Returns:\n",
    "    filtered_image_ids: list of image ids for each image in data[images] that has an annotation in filtered_annotation_ids\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_image_ids = set()\n",
    "    for image in data['images']:\n",
    "        if image['id'] in [annotation['image_id'] for annotation in data['annotations'] if annotation['id'] in filtered_annotation_ids]:\n",
    "            filtered_image_ids.add(image['id'])\n",
    "\n",
    "    return filtered_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(data, input_images_path, output_images_path, filtered_image_ids):\n",
    "    \"\"\"\n",
    "    Copy images from source_dir to destination_dir if the image id is in image_ids.\n",
    "\n",
    "    Input:\n",
    "    data: Dictionary containing 'images' and their details\n",
    "    input_images_path: Directory with images\n",
    "    destination_dir: Directory to move images to\n",
    "    image_ids: List of image ids for each image that should be moved\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    for image_id in filtered_image_ids:\n",
    "        # Find the image name for the given image ID\n",
    "        image_name = [image['file_name'] for image in data['images'] if image['id'] == image_id][0]\n",
    "        \n",
    "        # Construct source and destination file paths\n",
    "        source_path = os.path.join(input_images_path, image_name)\n",
    "        destination_path = os.path.join(output_images_path, image_name)\n",
    "        \n",
    "        # Ensure the destination directory exists\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        \n",
    "        # Copy the file from source to destination\n",
    "        shutil.copyfile(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_filtered_dataset(data, filtered_category_ids, filtered_annotation_ids, filtered_image_ids):\n",
    "    \"\"\"\n",
    "    Constructs a filtered dataset with only the categories, annotations and images that are in filtered_category_ids, filtered\n",
    "\n",
    "    Input:\n",
    "    data: json file with annotations. Dictionary with keyes: categories, annotations, images. Each dictionary contains a list of dictionaries.\n",
    "\n",
    "    Returns:\n",
    "    filtered_data: dictionary with only the categories, annotations and images that are in filtered_category_ids, filtered_annotation_ids and filtered_image_ids\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_data = dict()\n",
    "    filtered_data['categories'] = [category for category in data['categories'] if category['id'] in filtered_category_ids]\n",
    "    filtered_data['annotations'] = [annotation for annotation in data['annotations'] if annotation['id'] in filtered_annotation_ids]\n",
    "    filtered_data['images'] = [image for image in data['images'] if image['id'] in filtered_image_ids]\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_kids(input_file_path, kids_category_ids, output_file_path):\n",
    "    \"\"\"\n",
    "    Filters the COCO format annotations in the given JSON file based on the specified categories.\n",
    "    Creates a new image directory that includes the images in the original image directory that are also in the filtered annotations.\n",
    "    \n",
    "    Input:\n",
    "    - input_file_path (str): The path to the directory with the original annotations and images.\n",
    "    - all_category_dict (dict): A dictionary with category names as keys and their respective IDs as values.\n",
    "    - output_file_path (str): The path to the directory where the filtered JSON file and images will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    None: The function writes the filtered data to a file and does not return anything.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory is clean\n",
    "    if os.path.exists(output_file_path):\n",
    "        shutil.rmtree(output_file_path)\n",
    "    os.makedirs(output_file_path)  # Recreate the output directory\n",
    "    \n",
    "    # Define paths\n",
    "    input_ann_path = os.path.join(input_file_path, 'new_ann.json')\n",
    "    input_images_path = os.path.join(input_file_path, 'images')\n",
    "    output_ann_path = os.path.join(output_file_path, 'final_ann.json')\n",
    "    output_images_path = os.path.join(output_file_path, 'images')\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(input_ann_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # get filtered the category ids\n",
    "    filtered_category_ids = get_filtered_category_ids(data, kids_category_ids)\n",
    "\n",
    "    # get filtered the annotation ids\n",
    "    filtered_annotation_ids = get_filtered_annotation_ids(data, kids_category_ids)\n",
    "\n",
    "    # get filtered the image ids\n",
    "    filtered_image_ids = get_filtered_image_ids(data, filtered_annotation_ids)\n",
    "\n",
    "    # check that all filtered_image_ids are in the images directory\n",
    "    image_files = os.listdir(input_images_path)\n",
    "    image_ids = set([int(image_file.split('.')[0]) for image_file in image_files])\n",
    "    assert filtered_image_ids.issubset(image_ids), \"Not all filtered image ids are in the images directory\"\n",
    "\n",
    "    # construct the filtered dataset\n",
    "    filtered_data = construct_filtered_dataset(data, filtered_category_ids, filtered_annotation_ids, filtered_image_ids)\n",
    "\n",
    "    # write the filtered dataset to a new JSON file\n",
    "    with open(output_ann_path, 'w') as file:\n",
    "        json.dump(filtered_data, file)\n",
    "\n",
    "    # move the images\n",
    "    move_images(data, input_images_path, output_images_path, filtered_image_ids)\n",
    "\n",
    "    # print the number of categories, annotations and images in the filtered dataset\n",
    "    print(f\"Number of categories: {len(filtered_data['categories'])}\")\n",
    "    print(f\"Number of annotations: {len(filtered_data['annotations'])}\")\n",
    "    print(f\"Number of images: {len(filtered_data['images'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = '../bigdata/train'\n",
    "val_input_path = '../bigdata/val'\n",
    "\n",
    "train_output_path = '../filtered_data/train'\n",
    "val_output_path = '../filtered_data/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter kids data - validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 102\n",
      "Number of annotations: 782\n",
      "Number of images: 551\n"
     ]
    }
   ],
   "source": [
    "filter_data_kids(val_input_path, kids_category_ids, val_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter kids data - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 102\n",
      "Number of annotations: 36501\n",
      "Number of images: 23568\n"
     ]
    }
   ],
   "source": [
    "filter_data_kids(train_input_path, kids_category_ids, train_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all images in annotations are in the image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielmedina/Documents/Duke/classes/spring-2024/aipi540/AIPI540-project1/notebooks\n",
      "Number of missing images in the annotations: 0\n",
      "Number of non-missing images: 23568\n",
      "Number of missing images in the folder: 0\n"
     ]
    }
   ],
   "source": [
    "# print current directory\n",
    "print(os.getcwd())\n",
    "\n",
    "missing_images_ann = set()\n",
    "non_missing_images = set()\n",
    "missing_images_folder = set()\n",
    "\n",
    "with open('../filtered_data/train/final_ann.json') as f:\n",
    "  train_ann_filtered = json.load(f)\n",
    "\n",
    "for ann in train_ann_filtered['annotations']:\n",
    "    # get the category id of the annotation\n",
    "    ann_category_id = ann['category_id']\n",
    "    cat_found = False\n",
    "    for cat in train_ann_filtered['categories']:\n",
    "        if cat['id'] == ann_category_id:\n",
    "            cat_found = True\n",
    "            break\n",
    "    if not cat_found:\n",
    "        print('Error:', ann_category_id, 'not in train_ann_filtered')\n",
    "\n",
    "    # get the image id of the annotation\n",
    "    ann_image_id = ann['image_id']\n",
    "    img_found = False\n",
    "    for img in train_ann_filtered['images']:\n",
    "        if img['id'] == ann_image_id:\n",
    "            img_found = True\n",
    "            break\n",
    "    if not img_found:\n",
    "        missing_images_ann.add(ann_image_id)\n",
    "    \n",
    "    # get the file name of the image\n",
    "    ann_image_file_name = [img['file_name'] for img in train_ann_filtered['images'] if img['id'] == ann_image_id][0]\n",
    "    if ann_image_file_name not in os.listdir('../filtered_data/train/images'):\n",
    "        missing_images_folder.add(ann_image_file_name)\n",
    "    \n",
    "    # add the image_id to the non_missing_images set\n",
    "    non_missing_images.add(ann_image_id)\n",
    "\n",
    "print('Number of missing images in the annotations:', len(missing_images_ann))\n",
    "print('Number of non-missing images:', len(non_missing_images))\n",
    "print('Number of missing images in the folder:', len(missing_images_folder))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
