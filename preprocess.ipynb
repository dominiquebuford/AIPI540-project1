{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from skimage import io\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory: ../filtered_data/train/images\n",
      "Number of images in train directory: 23568\n",
      "Train annotations file: ../filtered_data/train/final_ann.json\n"
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "base_dir = \"../filtered_data\"\n",
    "train_images_dir = os.path.join(base_dir, \"train\", \"images\")\n",
    "train_ann_file = os.path.join(base_dir, \"train\", \"final_ann.json\")\n",
    "\n",
    "print(\"Train directory:\", train_images_dir)\n",
    "print(\"Number of images in train directory:\", len(os.listdir(train_images_dir)))\n",
    "print(\"Train annotations file:\", train_ann_file)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(train_ann_file) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the space at the end of the category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in data['categories']:\n",
    "  category['name_readable'] = category['name_readable'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the hog package from scikit-learn image libary, which is a popular open-source Python library package for image processing and computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    try:\n",
    "        image = io.imread(image_path)\n",
    "        # Check if the image is grayscale or color\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:  # Color image\n",
    "            features, hog_image = hog(image, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, channel_axis=-1)\n",
    "        else:  # Grayscale image\n",
    "            features, hog_image = hog(image, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "        return features\n",
    "    except FileNotFoundError:\n",
    "        # If the file is not found, return None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame(columns=[\"image\", \"features\", \"bbox\", \"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, train_images_dir):\n",
    "    # Initialize the counter for skipped images\n",
    "    skipped_images_count = 0\n",
    "\n",
    "    # Create a dictionary to map image IDs to file names\n",
    "    image_id_to_file_name = {image['id']: image['file_name'] for image in data['images']}\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame(columns=[\"image\", \"features\", \"bbox\", \"category\"])\n",
    "\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        image_name = image_id_to_file_name[image_id]\n",
    "        image_path = os.path.join(train_images_dir, image_name)\n",
    "\n",
    "        # check if image exists\n",
    "        if not Path(image_path).is_file():\n",
    "            print(f\"Image {image_id} not found\")\n",
    "            skipped_images_count = 0\n",
    "            continue\n",
    "\n",
    "        # Attempt to extract features\n",
    "        features = extract_features(image_path)\n",
    "\n",
    "        # Check if features were successfully extracted\n",
    "        if features is not None:\n",
    "            # Append to DataFrame if features are found\n",
    "            temp_df = pd.DataFrame({\n",
    "                \"image\": [image_id],\n",
    "                \"features\": [features],\n",
    "                \"bbox\": [ann['bbox']],\n",
    "                \"category\": [ann['category_id']]\n",
    "            })\n",
    "            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        else:\n",
    "            # Increment the counter if the image was skipped\n",
    "            skipped_images_count += 1\n",
    "\n",
    "    # After the loop\n",
    "    print(f\"Number of skipped images: {skipped_images_count}\")\n",
    "    # Save DataFrame\n",
    "    df.to_csv(\"output/image_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skipped images: 0\n"
     ]
    }
   ],
   "source": [
    "generate_features(data, train_images_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
